{"cells":[{"cell_type":"markdown","metadata":{"id":"rFB64iL9BzBd"},"source":["StyleGAN2-ADA 모델은 텐서플로우 1 버전에서만 작동"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1654518192709,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"fbyUpDO4OLiU","outputId":"de1cbac0-725c-4be4-aedc-3bd2d0106ee6"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x     "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2430,"status":"ok","timestamp":1654518248021,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"F--t1T_uoaGg","outputId":"7160256d-3fbc-4dbf-c11d-79f2cb650016"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"]}],"source":["!pip install numpy==1.19.5"]},{"cell_type":"markdown","metadata":{"id":"91s4Bdk2CAJi"},"source":["현재 코랩에서 어떤 GPU를 할당받았는지 확인하는 코드."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1654441990576,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"KiBLUTr7OVoB","outputId":"3ed7934d-5c40-47cf-a5ef-ebfbd3d0b411"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun  5 15:13:38 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"WhGEeUh8CEMc"},"source":["구글드라이브와 현재 코랩을 연동."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15060,"status":"ok","timestamp":1654518240576,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"F46YSLmVOWWa","outputId":"d231da15-86c7-44e1-b48f-3f9665571be0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"F1jG7Cx1RWKY"},"source":[" 깃허브에서 StyleGAN2-ADA를 코랩으로 불러와 다운로드 "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2800,"status":"ok","timestamp":1654518245594,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"CVtHBVKbOmKl","outputId":"b7b18342-7813-4ebc-df51-a6688d554d33"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'stylegan2-ada'...\n","remote: Enumerating objects: 364, done.\u001b[K\n","remote: Total 364 (delta 0), reused 0 (delta 0), pack-reused 364\u001b[K\n","Receiving objects: 100% (364/364), 56.17 MiB | 42.42 MiB/s, done.\n","Resolving deltas: 100% (197/197), done.\n"]}],"source":["# Download the code\n","%cd /content/\n","!git clone https://github.com/dvschultz/stylegan2-ada.git\n","!mkdir downloads\n","!mkdir datasets"]},{"cell_type":"markdown","metadata":{"id":"ffxQiIkQRTGO"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"oa5ILnoJXNXq"},"source":["데이터셋은 압축하여 .zip형태로 구글드라이브에 저장 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w637CVdoO3du"},"outputs":[],"source":["dataset_name = \"celeb\"   "]},{"cell_type":"markdown","metadata":{"id":"6NKBXJsUC1Cc"},"source":["코랩으로 데이터셋 압축파일을 불러와서 압축을 품"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3047,"status":"ok","timestamp":1654442022193,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"_tdy-VknQbkW","outputId":"24252861-9096-455d-8d53-af0f91c3a676"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting all the files now...\n","Done!\n"]}],"source":["import zipfile\n","path = \"/content/drive/MyDrive/Colab Notebooks/datasets/\"\n","dataset = dataset_name + \".zip\"\n","local_path = \"/content/\"\n","file_name = path + dataset\n","with zipfile.ZipFile(file_name, 'r') as zip:\n","   #zip.printdir()\n","   print('Extracting all the files now...') \n","   zip.extractall(local_path) \n","   print('Done!')"]},{"cell_type":"markdown","metadata":{"id":"bxtOLRCvDULH"},"source":["불러온 이미지 데이터셋 jpg 파일들을 텐서플로에서 사용할 수 있는 데이터셋 포맷(tfrecords)으로 바꿔야 함"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42671,"status":"ok","timestamp":1654442067238,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"BlS7sB4xQtmC","outputId":"3d8ff6c9-cdfa-4ecc-8944-c32fd140bfd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/stylegan2-ada\n","Loading images from \"/content/drive/MyDrive/data\"\n","Creating dataset \"/content/datasets/celeb\"\n","dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n","  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n","Added 70 images.\n"]}],"source":["%cd /content/\n","\n","#update this to the path to your image folder\n","dataset_folder_name = 'drive/MyDrive/data' # name of zip file may be different from folder name it extracted to\n","dataset_path = \"/content/\" + dataset_folder_name\n","\n","\n","#you don't need to edit anything here\n","%cd /content/stylegan2-ada\n","!python dataset_tool.py create_from_images /content/datasets/{dataset_name} {dataset_path}"]},{"cell_type":"markdown","metadata":{"id":"fyhe_tggRPnq"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"CrikBYS-VOnO"},"source":["학습할 때 조절가능한 다양한 파라미터들을 --help를 통해 확인 가능 "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4202,"status":"ok","timestamp":1654518285221,"user":{"displayName":"심규철","userId":"14369931663006027533"},"user_tz":-540},"id":"UPPicfQXQ_PZ","outputId":"687b5a7f-563f-4ef3-be90-be92e4834a60"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2-ada\n","usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n","                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n","                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n","                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n","                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n","                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n","                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n","                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n","                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n","                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n","\n","Train a GAN using the techniques described in the paper\n","\"Training Generative Adversarial Networks with Limited Data\".\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","\n","general options:\n","  --outdir DIR          Where to save the results (required)\n","  --gpus INT            Number of GPUs to use (default: 1 gpu)\n","  --snap INT            Snapshot interval (default: 50 ticks)\n","  --seed INT            Random seed (default: 1000)\n","  -n, --dry-run         Print training options and exit\n","\n","training dataset:\n","  --data PATH           Training dataset path (required)\n","  --res INT             Dataset resolution (default: highest available)\n","  --mirror BOOL         Augment dataset with x-flips (default: false)\n","  --mirrory BOOL        Augment dataset with y-flips (default: false)\n","  --use-raw BOOL        Use raw image dataset, i.e. created from\n","                        create_from_images_raw (default: False)\n","\n","metrics:\n","  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n","  --metricdata PATH     Dataset to evaluate metrics against (optional)\n","\n","base config:\n","  --cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}\n","                        Base config (default: auto)\n","  --lrate FLOAT         Override learning rate\n","  --ttur BOOL           Use Two Time-Scale Update Rule (double learning rate\n","                        for discriminator) (default: false)\n","  --gamma FLOAT         Override R1 gamma\n","  --nkimg INT           Override starting count\n","  --kimg INT            Override training duration\n","  --topk FLOAT          utilize top-k training\n","\n","discriminator augmentation:\n","  --aug {noaug,ada,fixed,adarv}\n","                        Augmentation mode (default: ada)\n","  --p FLOAT             Specify augmentation probability for --aug=fixed\n","  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n","  --initstrength INITSTRENGTH\n","                        Override ADA strength at start\n","  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n","                        Augmentation pipeline (default: bgc)\n","\n","comparison methods:\n","  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n","                        Comparison method (default: nocmethod)\n","  --dcap FLOAT          Multiplier for discriminator capacity\n","\n","transfer learning:\n","  --resume RESUME       Resume from network pickle (default: noresume)\n","  --freezed INT         Freeze-D (default: 0 discriminator layers)\n","\n","examples:\n","\n","  # Train custom dataset using 1 GPU.\n","  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n","\n","  # Train class-conditional CIFAR-10 using 2 GPUs.\n","  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n","      --cfg=cifar\n","\n","  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n","  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n","      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n","\n","  # Reproduce original StyleGAN2 config F.\n","  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n","      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n","\n","available base configs (--cfg):\n","  auto           Automatically select reasonable defaults based on resolution\n","                 and GPU count. Good starting point for new datasets.\n","  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n","  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n","  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n","  paper1024      Reproduce results for MetFaces at 1024x1024.\n","  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n","  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n","\n","transfer learning source networks (--resume):\n","  ffhq256        FFHQ trained at 256x256 resolution.\n","  ffhq512        FFHQ trained at 512x512 resolution.\n","  ffhq1024       FFHQ trained at 1024x1024 resolution.\n","  celebahq256    CelebA-HQ trained at 256x256 resolution.\n","  lsundog256     LSUN Dog trained at 256x256 resolution.\n","  afhqcat512     AFHQ Cat trained at 512x512 resolution.\n","  afhqdog512     AFHQ Dog trained at 512x512 resolution.\n","  afhqwild512    AFHQ Wild trained at 512x512 resolution.\n","  brecahad512    BreCaHAD trained at 512x512 resolution.\n","  cifar10        CIFAR10 trained at 32x32 resolution.\n","  metfaces512    MetFaces trained at 512x512 resolution.\n","  <path or URL>  Custom network pickle.\n"]}],"source":["%cd /content/stylegan2-ada\n","!python train.py --help"]},{"cell_type":"markdown","metadata":{"id":"nhlt3UUwVWmg"},"source":["아래 셀을 실행하면 학습이 시작되고 학습이 진행되는 동안에는 이 노트북 브라우저 창을 열어두어야 함. 노트북 창을 닫거나 인터넷 연결 종료, 오랜시간동안 실행되고 있는 경우 등으로 연결이 끊기면 처음 셀부터 다시 실행해야 함. resume_form의 경로를 최근 pkl파일 경로로 바꿔주면 이어서 학습이 가능함 \n","\n","학습이 진행되는 동안 구글 드라이브 폴더를 확인하면 중간 과정의 이미지 경과물과 모델을 확인 가능 \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"yo53TCYVRKW0","outputId":"b31ea01c-d874-453c-c8c6-43baa637f94a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tcmalloc: large alloc 4294967296 bytes == 0x8550000 @  0x7fac0d61e001 0x7fac0a82254f 0x7fac0a872b58 0x7fac0a876b17 0x7fac0a915203 0x593835 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n","tcmalloc: large alloc 4294967296 bytes == 0x7faa246cc000 @  0x7fac0d61c1e7 0x7fac0a82246e 0x7fac0a872c7b 0x7fac0a87335f 0x7fac0a915103 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n","tcmalloc: large alloc 4294967296 bytes == 0x7fa9236ca000 @  0x7fac0d61c1e7 0x7fac0a82246e 0x7fac0a872c7b 0x7fac0a87335f 0x7fabb643c235 0x7fabb5dbf792 0x7fabb5dbfd42 0x7fabb5d78aee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n","\n","Training options:\n","{\n","  \"G_args\": {\n","    \"func_name\": \"training.networks.G_main\",\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"mapping_layers\": 2,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"D_args\": {\n","    \"func_name\": \"training.networks.D_main\",\n","    \"mbstd_group_size\": 4,\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"D_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"loss_args\": {\n","    \"func_name\": \"training.loss.stylegan2\",\n","    \"r1_gamma\": 1.0\n","  },\n","  \"augment_args\": {\n","    \"class_name\": \"training.augment.AdaptiveAugment\",\n","    \"tune_heuristic\": \"rt\",\n","    \"tune_target\": 0.6,\n","    \"apply_func\": \"training.augment.augment_pipeline\",\n","    \"apply_args\": {\n","      \"xflip\": 1,\n","      \"rotate90\": 1,\n","      \"xint\": 1,\n","      \"scale\": 1,\n","      \"rotate\": 1,\n","      \"aniso\": 1,\n","      \"xfrac\": 1,\n","      \"brightness\": 1,\n","      \"contrast\": 1,\n","      \"lumaflip\": 1,\n","      \"hue\": 1,\n","      \"saturation\": 1\n","    },\n","    \"tune_kimg\": 100\n","  },\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 1,\n","  \"network_snapshot_ticks\": 1,\n","  \"train_dataset_args\": {\n","    \"path\": \"/content/datasets/celeb\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": false\n","  },\n","  \"metric_arg_list\": [],\n","  \"metric_dataset_args\": {\n","    \"path\": \"/content/datasets/celeb\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": false\n","  },\n","  \"total_kimg\": 25000,\n","  \"minibatch_size\": 4,\n","  \"minibatch_gpu\": 4,\n","  \"G_smoothing_kimg\": 1.25,\n","  \"G_smoothing_rampup\": null,\n","  \"resume_pkl\": \"/content/drive/MyDrive/Colab Notebooks/results/celeb/00005-celeb-mirror-auto1-gamma1-resumecustom/network-snapshot-000028.pkl\",\n","  \"run_dir\": \"/content/drive/MyDrive/Colab Notebooks/results/celeb/00006-celeb-mirror-auto1-gamma1-resumecustom\"\n","}\n","\n","Output directory:  /content/drive/MyDrive/Colab Notebooks/results/celeb/00006-celeb-mirror-auto1-gamma1-resumecustom\n","Training data:     /content/datasets/celeb\n","Training length:   25000 kimg\n","Resolution:        1024\n","Number of GPUs:    1\n","\n","Creating output directory...\n","Loading training set...\n","tcmalloc: large alloc 4294967296 bytes == 0x824e000 @  0x7fac0d61e001 0x7fac0a82254f 0x7fac0a872b58 0x7fac0a876b17 0x7fac0a915203 0x593835 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n","tcmalloc: large alloc 4294967296 bytes == 0x7fa81804c000 @  0x7fac0d61c1e7 0x7fac0a82246e 0x7fac0a872c7b 0x7fac0a87335f 0x7fac0a915103 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n","tcmalloc: large alloc 4294967296 bytes == 0x7fa81804c000 @  0x7fac0d61c1e7 0x7fac0a82246e 0x7fac0a872c7b 0x7fac0a87335f 0x7fabb643c235 0x7fabb5dbf792 0x7fabb5dbfd42 0x7fabb5d78aee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n","Image shape: [3, 1024, 1024]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n","Resuming from \"/content/drive/MyDrive/Colab Notebooks/results/celeb/00005-celeb-mirror-auto1-gamma1-resumecustom/network-snapshot-000028.pkl\"\n","\n","G                               Params    OutputShape          WeightShape     \n","---                             ---       ---                  ---             \n","latents_in                      -         (?, 512)             -               \n","labels_in                       -         (?, 0)               -               \n","epochs                          1         ()                   ()              \n","epochs_1                        1         ()                   ()              \n","G_mapping/Normalize             -         (?, 512)             -               \n","G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n","G_mapping/Broadcast             -         (?, 18, 512)         -               \n","dlatent_avg                     -         (512,)               -               \n","Truncation/Lerp                 -         (?, 18, 512)         -               \n","G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n","G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n","G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n","G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n","G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n","G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n","G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n","G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n","G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n","G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n","G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n","---                             ---       ---                  ---             \n","Total                           28794126                                       \n","\n","\n","D                     Params    OutputShape          WeightShape     \n","---                   ---       ---                  ---             \n","images_in             -         (?, 3, 1024, 1024)   -               \n","labels_in             -         (?, 0)               -               \n","1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n","1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n","1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n","512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n","512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n","256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n","256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n","256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n","128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n","128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n","128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n","64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n","64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n","32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n","16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n","8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n","8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n","4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n","4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n","4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n","Output                513       (?, 1)               (512, 1)        \n","---                   ---       ---                  ---             \n","Total                 29012513                                       \n","\n","Exporting sample images...\n","Replicating networks across 1 GPUs...\n","Initializing augmentations...\n","Setting up optimizers...\n","Constructing training graph...\n","Finalizing training ops...\n","Initializing metrics...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 2m 05s       sec/tick 35.8    sec/kimg 2239.95 maintenance 89.0   gpumem 10.1  augment 0.000\n","tick 1     kimg 4.0      time 43m 28s      sec/tick 2468.1  sec/kimg 617.03  maintenance 15.5   gpumem 10.1  augment 0.038\n","tick 2     kimg 8.0      time 1h 25m 01s   sec/tick 2489.4  sec/kimg 622.34  maintenance 3.6    gpumem 10.1  augment 0.075\n","tick 3     kimg 12.0     time 2h 06m 41s   sec/tick 2496.3  sec/kimg 624.07  maintenance 3.6    gpumem 10.1  augment 0.113\n","tick 4     kimg 16.0     time 2h 48m 33s   sec/tick 2508.2  sec/kimg 627.04  maintenance 3.5    gpumem 10.1  augment 0.150\n","tick 5     kimg 20.0     time 3h 30m 35s   sec/tick 2516.8  sec/kimg 629.20  maintenance 4.8    gpumem 10.1  augment 0.186\n","tick 6     kimg 24.0     time 4h 12m 44s   sec/tick 2526.3  sec/kimg 631.57  maintenance 3.5    gpumem 10.1  augment 0.221\n","tick 7     kimg 28.0     time 4h 55m 02s   sec/tick 2533.6  sec/kimg 633.39  maintenance 3.5    gpumem 10.1  augment 0.256\n","tick 8     kimg 32.0     time 5h 37m 29s   sec/tick 2543.4  sec/kimg 635.84  maintenance 3.7    gpumem 10.1  augment 0.289\n","tick 9     kimg 36.0     time 6h 20m 04s   sec/tick 2551.5  sec/kimg 637.88  maintenance 3.7    gpumem 10.1  augment 0.319\n","tick 10    kimg 40.0     time 7h 02m 47s   sec/tick 2559.5  sec/kimg 639.88  maintenance 3.6    gpumem 10.1  augment 0.348\n","tick 11    kimg 44.0     time 7h 45m 34s   sec/tick 2563.5  sec/kimg 640.89  maintenance 3.7    gpumem 10.1  augment 0.378\n","tick 12    kimg 48.0     time 8h 28m 30s   sec/tick 2572.1  sec/kimg 643.03  maintenance 4.2    gpumem 10.1  augment 0.407\n"]}],"source":["# output directory 결과물 저장 경로 \n","output_dir = '/content/drive/MyDrive/Colab\\ Notebooks/results/' + dataset_name + \"/\"\n","\n","# config\n","config = \"auto\"\n","\n","# gamma\n","gamma = 1\n","\n","# 학습진행 중 몇번째마다 저장할것인지 \n","snapshot_count = 1\n","\n","# 좌우반전\n","mirrored = True\n","# 상하 반전 \n","mirroredY = False\n","\n","#metrics\n","metric_list = None\n","\n","# 학습을 이어하기 위한 resum_from\n","resume_from = \"/content/drive/MyDrive/Colab\\ Notebooks/results/celeb/00005-celeb-mirror-auto1-gamma1-resumecustom/network-snapshot-000028.pkl\"\n","\n","\n","# 위의 파라미터들을 이용한 학습시작 \n","!python train.py --outdir={output_dir} \\\n","                 --cfg={config} \\\n","                 --snap={snapshot_count} \\\n","                 --data=/content/datasets/{dataset_name} \\\n","                 --mirror={mirrored} --mirrory={mirroredY} \\\n","                 --gamma={gamma} \\\n","                 --metrics={metric_list} \\\n","                 --resume={resume_from}"]},{"cell_type":"code","source":["!python generate.py --outdir=/content/out/images/ --trunc=0.8 --seeds=0 --network=/content/drive/MyDrive/ladiescrop-network-snapshot-012885.pkl"],"metadata":{"id":"IBOPE76Z94Yn"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"StylegGAN2-ADA .ipynb","provenance":[{"file_id":"1YMzIIiDQPf7q9USAMOZ9zSV0nUT36LHt","timestamp":1653555072335}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}